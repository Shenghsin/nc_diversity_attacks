{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeR2kRlPR7v0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IByUFiD8VfFD",
    "outputId": "d60948fc-a5cf-4386-c10d-2960ca8cb51f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 100\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print('CUDA is not available.  Training on CPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7l36L4F5VifU"
   },
   "outputs": [],
   "source": [
    "#  torchvision.transforms.Normalize(\n",
    "#    (0.1307,), (0.3081,))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('/data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "    batch_size=batch_size_train, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('/data/', train=False, download=True,\n",
    "                         transform=torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor()\n",
    "                         ])),\n",
    "    batch_size=batch_size_test, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKEku0wcSCVQ"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.dens1 = nn.Linear(784, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.dens2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "        self.dens3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "        self.dens4 = nn.Linear(64, 20)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.drop4 = nn.Dropout(0.2)\n",
    "        self.dens5 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dens1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.dens2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.dens3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.dens4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.drop4(x)\n",
    "        x = self.dens5(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def extract_outputs(self, x, layer, neuron=None):\n",
    "        outputs = []\n",
    "        \n",
    "        def hook(module, input, output):\n",
    "            outputs.append(output)    \n",
    "            \n",
    "        for name, module in self.named_children():\n",
    "            if name == layer:\n",
    "                handle = module.register_forward_hook(hook)   \n",
    "                \n",
    "        out = self(x)\n",
    "        \n",
    "        if not neuron is None:\n",
    "            outputs[0] = outputs[0][0][neuron]\n",
    "   \n",
    "        handle.remove()\n",
    "  \n",
    "        return outputs\n",
    "  \n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # calculate robust loss\n",
    "        loss = F.cross_entropy(model(data), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCva0V7uVIZ_"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "elqqm9cYVRuM",
    "outputId": "9b3ba6c3-0a78-4d54-f952-65fc10b7160e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302933\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.300855\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.309253\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.309311\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.300814\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.287257\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.299283\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.286950\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.282867\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.275136\n",
      "\n",
      "Test set: Average loss: 2.2600, Accuracy: 1820/10000 (18%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.277891\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.238356\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.216121\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 2.168850\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.978635\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.752849\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.572883\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.390635\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.215070\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.025876\n",
      "\n",
      "Test set: Average loss: 0.9178, Accuracy: 6922/10000 (69%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.155205\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.054240\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.830142\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.160316\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.885689\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.725319\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.603057\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.774410\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.526434\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.799807\n",
      "\n",
      "Test set: Average loss: 0.5027, Accuracy: 8524/10000 (85%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.739905\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.777653\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.475673\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.506253\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.570428\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.663706\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.590834\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.448712\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.710306\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.502982\n",
      "\n",
      "Test set: Average loss: 0.3173, Accuracy: 9107/10000 (91%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.355999\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.538407\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.293430\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.381199\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.466247\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.621231\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.313687\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.260217\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.225912\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.288945\n",
      "\n",
      "Test set: Average loss: 0.2264, Accuracy: 9383/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xXXilwbZq-v"
   },
   "source": [
    "# Attack Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbAGYjiGODjF"
   },
   "outputs": [],
   "source": [
    "targeted=True\n",
    "confidence=0.0\n",
    "c_range=(1e-3, 1e10)\n",
    "search_steps=5\n",
    "max_steps=1000\n",
    "abort_early=True\n",
    "box=(-1., 1.)\n",
    "optimizer_lr=1e-2\n",
    "\n",
    "log_frequency = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Im4wutR6ge14"
   },
   "outputs": [],
   "source": [
    "def atanh(x, eps=1e-2):\n",
    "    \"\"\"\n",
    "    The inverse hyperbolic tangent function, missing in pytorch.\n",
    "\n",
    "    :param x: a tensor or a Variable\n",
    "    :param eps: used to enhance numeric stability\n",
    "    :return: :math:`\\\\tanh^{-1}{x}`, of the same type as ``x``\n",
    "    \"\"\"\n",
    "    x = x * (1 - eps)\n",
    "    return 0.5 * torch.log((1.0 + x) / (1.0 - x))\n",
    "\n",
    "def to_tanh_space(x, box=box):\n",
    "    \"\"\"\n",
    "    Convert a batch of tensors to tanh-space. This method complements the\n",
    "    implementation of the change-of-variable trick in terms of tanh.\n",
    "\n",
    "    :param x: the batch of tensors, of dimension [B x C x H x W]\n",
    "    :param box: a tuple of lower bound and upper bound of the box constraint\n",
    "    :return: the batch of tensors in tanh-space, of the same dimension;\n",
    "             the returned tensor is on the same device as ``x``\n",
    "    \"\"\"\n",
    "    _box_mul = (box[1] - box[0]) * 0.5\n",
    "    _box_plus = (box[1] + box[0]) * 0.5\n",
    "    return atanh((x - _box_plus) / _box_mul)\n",
    "\n",
    "def from_tanh_space(x, box=box):\n",
    "    \"\"\"\n",
    "    Convert a batch of tensors from tanh-space to oridinary image space.\n",
    "    This method complements the implementation of the change-of-variable trick\n",
    "    in terms of tanh.\n",
    "\n",
    "    :param x: the batch of tensors, of dimension [B x C x H x W]\n",
    "    :param box: a tuple of lower bound and upper bound of the box constraint\n",
    "    :return: the batch of tensors in ordinary image space, of the same\n",
    "             dimension; the returned tensor is on the same device as ``x``\n",
    "    \"\"\"\n",
    "    _box_mul = (box[1] - box[0]) * 0.5\n",
    "    _box_plus = (box[1] + box[0]) * 0.5\n",
    "    return torch.tanh(x) * _box_mul + _box_plus\n",
    "  \n",
    "def compensate_confidence(outputs, targets):\n",
    "    \"\"\"\n",
    "    Compensate for ``self.confidence`` and returns a new weighted sum\n",
    "    vector.\n",
    "\n",
    "    :param outputs: the weighted sum right before the last layer softmax\n",
    "           normalization, of dimension [B x M]\n",
    "    :type outputs: np.ndarray\n",
    "    :param targets: either the attack targets or the real image labels,\n",
    "           depending on whether or not ``self.targeted``, of dimension [B]\n",
    "    :type targets: np.ndarray\n",
    "    :return: the compensated weighted sum of dimension [B x M]\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "    outputs_comp = outputs.clone()\n",
    "    rng = torch.range(start=0, end=targets.shape[0]-1, dtype=torch.long, device=device)\n",
    "    # targets = targets.int()\n",
    "    if targeted:\n",
    "        # for each image $i$:\n",
    "        # if targeted, `outputs[i, target_onehot]` should be larger than\n",
    "        # `max(outputs[i, ~target_onehot])` by `self.confidence`\n",
    "        outputs_comp[rng, targets] -= confidence\n",
    "    else:\n",
    "        # for each image $i$:\n",
    "        # if not targeted, `max(outputs[i, ~target_onehot]` should be larger\n",
    "        # than `outputs[i, target_onehot]` (the ground truth image labels)\n",
    "        # by `self.confidence`\n",
    "        outputs_comp[rng, targets] += confidence\n",
    "    return outputs_comp\n",
    "  \n",
    "def attack_successful(prediction, target):\n",
    "    \"\"\"\n",
    "    See whether the underlying attack is successful.\n",
    "\n",
    "    :param prediction: the prediction of the model on an input\n",
    "    :type prediction: int\n",
    "    :param target: either the attack target or the ground-truth image label\n",
    "    :type target: int\n",
    "    :return: ``True`` if the attack is successful\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    if targeted:\n",
    "        return prediction == target\n",
    "    else:\n",
    "        return prediction != target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7o_T3B3dWzu"
   },
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(test_loader))\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "KiGJy0r2h4aJ",
    "outputId": "bd617c85-ab10-481a-8e22-d956ba3d6381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "batch [0] loss: 0.9280296564102173\n",
      "batch [100] loss: 0.018136832863092422\n",
      "batch [200] loss: 0.014460964128375053\n",
      "batch [300] loss: 0.013831041753292084\n",
      "batch [400] loss: 0.013599553145468235\n",
      "batch [500] loss: 0.013476535677909851\n",
      "batch [600] loss: 0.013400744646787643\n",
      "batch [700] loss: 0.013350140303373337\n",
      "batch [800] loss: 0.013314418494701385\n",
      "batch [900] loss: 0.013288169167935848\n",
      "Step 1\n",
      "batch [0] loss: 0.12307195365428925\n",
      "batch [100] loss: 0.12085845321416855\n",
      "batch [200] loss: 0.12082726508378983\n",
      "batch [300] loss: 0.12097981572151184\n",
      "Step 2\n",
      "batch [0] loss: 1.1789371967315674\n",
      "batch [100] loss: 0.9674735069274902\n",
      "batch [200] loss: 0.9636998176574707\n",
      "batch [300] loss: 0.9595181941986084\n",
      "batch [400] loss: 0.9552007913589478\n",
      "batch [500] loss: 0.9665858745574951\n",
      "Step 3\n",
      "batch [0] loss: 7.730571269989014\n",
      "batch [100] loss: 2.361110210418701\n",
      "batch [200] loss: 2.3970932960510254\n",
      "Step 4\n",
      "batch [0] loss: 2.330204486846924\n",
      "batch [100] loss: 2.004525661468506\n",
      "batch [200] loss: 2.016444683074951\n"
     ]
    }
   ],
   "source": [
    "batch_size = inputs.size(0)\n",
    "num_classes = model(torch.tensor(inputs[0], requires_grad=False)).size(1)\n",
    "\n",
    "# `lower_bounds`, `upper_bounds` and `scale_consts` are used\n",
    "# for binary search of each `scale_const` in the batch. The element-wise\n",
    "# inquality holds: lower_bounds < scale_consts <= upper_bounds\n",
    "lower_bounds = torch.tensor(np.zeros(batch_size), dtype=torch.float, device=device)\n",
    "upper_bounds = torch.tensor(np.ones(batch_size) * c_range[1], dtype=torch.float, device=device)\n",
    "scale_consts = torch.tensor(np.ones(batch_size) * c_range[0], dtype=torch.float, device=device)\n",
    "\n",
    "# Optimal attack to be found.\n",
    "# The three \"placeholders\" are defined as:\n",
    "# - `o_best_l2`          : the least L2 norms\n",
    "# - `o_best_l2_ppred`    : the perturbed predictions made by the adversarial perturbations with the least L2 norms\n",
    "# - `o_best_adversaries` : the underlying adversarial example of `o_best_l2_ppred`\n",
    "o_best_l2 = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
    "o_best_l2_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
    "o_best_adversaries = inputs.clone()\n",
    "\n",
    "# convert `inputs` to tanh-space\n",
    "inputs_tanh = to_tanh_space(inputs)\n",
    "targets_oh = F.one_hot(targets).float()\n",
    "\n",
    "# the perturbation tensor (only one we need to track gradients on)\n",
    "pert_tanh = torch.zeros(inputs.size(), device=device, requires_grad=True)\n",
    "\n",
    "optimizer = optim.Adam([pert_tanh], lr=optimizer_lr)\n",
    "\n",
    "for const_step in range(search_steps):\n",
    "  \n",
    "    print('Step', const_step)\n",
    "    \n",
    "    # the minimum L2 norms of perturbations found during optimization\n",
    "    best_l2 = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
    "    \n",
    "    # the perturbed predictions made by the adversarial perturbations with the least L2 norms\n",
    "    best_l2_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
    "    \n",
    "    # previous (summed) batch loss, to be used in early stopping policy\n",
    "    prev_batch_loss = torch.tensor(np.inf, device=device)\n",
    "    ae_tol = torch.tensor(1e-4, device=device)\n",
    "    \n",
    "    # optimization steps\n",
    "    for optim_step in range(max_steps):\n",
    "        \n",
    "        adversaries = from_tanh_space(inputs_tanh + pert_tanh)\n",
    "        pert_outputs = model(adversaries)\n",
    "\n",
    "        # Calculate L2 norm between adversaries and original inputs\n",
    "        pert_norms = torch.pow(adversaries - inputs, exponent=2)\n",
    "        pert_norms = torch.sum(pert_norms.view(pert_norms.size(0), -1), 1)\n",
    "\n",
    "        target_activ = torch.sum(targets_oh * pert_outputs, 1)\n",
    "        maxother_activ = torch.max(((1 - targets_oh) * pert_outputs - targets_oh * 1e4), 1)[0]\n",
    "\n",
    "        if targeted:           \n",
    "            # if targeted, optimize to make `target_activ` larger than `maxother_activ` by `confidence`\n",
    "            f = torch.clamp(maxother_activ - target_activ + confidence, min=0.0)\n",
    "        else:\n",
    "            # if not targeted, optimize to make `maxother_activ` larger than `target_activ` (the ground truth image labels) by `confidence`\n",
    "            f = torch.clamp(target_activ - maxother_activ + confidence, min=0.0)\n",
    "\n",
    "        # the total loss of current batch, should be of dimension [1]\n",
    "        batch_loss = torch.sum(pert_norms + scale_consts * f)\n",
    "\n",
    "        # Do optimization for one step\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # \"returns\" batch_loss, pert_norms, pert_outputs, adversaries\n",
    "\n",
    "        if optim_step % log_frequency == 0: print('batch [{}] loss: {}'.format(optim_step, batch_loss))\n",
    "\n",
    "        if abort_early and not optim_step % (max_steps // 10):\n",
    "            \n",
    "            if batch_loss > prev_batch_loss * (1 - ae_tol):\n",
    "                break\n",
    "            prev_batch_loss = batch_loss\n",
    "\n",
    "        # update best attack found during optimization\n",
    "        pert_predictions = torch.argmax(pert_outputs, dim=1)\n",
    "        comp_pert_predictions = torch.argmax(compensate_confidence(pert_outputs, targets), dim=1)\n",
    "        for i in range(batch_size):\n",
    "            l2 = pert_norms[i]\n",
    "            cppred = comp_pert_predictions[i]\n",
    "            ppred = pert_predictions[i]\n",
    "            tlabel = targets[i]\n",
    "            ax = adversaries[i]\n",
    "            if attack_successful(cppred, tlabel):\n",
    "                assert cppred == ppred\n",
    "                if l2 < best_l2[i]:\n",
    "                    best_l2[i] = l2\n",
    "                    best_l2_ppred[i] = ppred\n",
    "                if l2 < o_best_l2[i]:\n",
    "                    o_best_l2[i] = l2\n",
    "                    o_best_l2_ppred[i] = ppred\n",
    "                    o_best_adversaries[i] = ax\n",
    "                    \n",
    "    # binary search of `scale_const`\n",
    "    for i in range(batch_size):\n",
    "        tlabel = targets[i]\n",
    "        if best_l2_ppred[i] != -1:\n",
    "            # successful: attempt to lower `scale_const` by halving it\n",
    "            if scale_consts[i] < upper_bounds[i]:\n",
    "                upper_bounds[i] = scale_consts[i]\n",
    "            # `upper_bounds[i] == c_range[1]` implies no solution\n",
    "            # found, i.e. upper_bounds[i] has never been updated by\n",
    "            # scale_consts[i] until `scale_consts[i] > 0.1 * c_range[1]`\n",
    "            if upper_bounds[i] < c_range[1] * 0.1:\n",
    "                scale_consts[i] = (lower_bounds[i] + upper_bounds[i]) / 2\n",
    "        else:\n",
    "            # failure: multiply `scale_const` by ten if no solution\n",
    "            # found; otherwise do binary search\n",
    "            if scale_consts[i] > lower_bounds[i]:\n",
    "                lower_bounds[i] = scale_consts[i]\n",
    "            if upper_bounds[i] < c_range[1] * 0.1:\n",
    "                scale_consts[i] = (lower_bounds[i] + upper_bounds[i]) / 2\n",
    "            else:\n",
    "                scale_consts[i] *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "CUsvsyleV1Is",
    "outputId": "b947aac7-e73b-4d41-e3f0-9228a53e2b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbed Accuracy: 100/100 (100%)\n",
      "\n",
      "Original Accuracy: 95/100 (95%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADkCAYAAADNX7BjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIuIlDVAiIuIlDVAiIuIlDVAiIuKl/w85UcW5cBtOkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pert_output = model(o_best_adversaries)\n",
    "orig_output = model(inputs)\n",
    "\n",
    "pert_pred = torch.argmax(pert_output, dim=1)\n",
    "orig_pred = torch.argmax(orig_output, dim=1)\n",
    "\n",
    "pert_correct = pert_pred.eq(targets.data).sum()\n",
    "orig_correct = orig_pred.eq(targets.data).sum()\n",
    "\n",
    "pert_acc = 100. * pert_correct / len(targets)\n",
    "orig_acc = 100. * orig_correct / len(targets)\n",
    "\n",
    "print('Perturbed Accuracy: {}/{} ({:.0f}%)\\n'.format(pert_correct, len(targets), pert_acc))\n",
    "print('Original Accuracy: {}/{} ({:.0f}%)\\n'.format(orig_correct, len(targets), orig_acc))\n",
    "\n",
    "adversarial_examples = o_best_adversaries.cpu().detach().numpy()\n",
    "input_examples = inputs.cpu().detach().numpy()\n",
    "\n",
    "# inputs, adversarial_examples, targets\n",
    "num_samples = 5\n",
    "\n",
    "for i in range(1,num_samples+1):\n",
    "    \n",
    "    plt.subplot(2, num_samples, i)\n",
    "    plt.imshow(np.squeeze(input_examples[i]))  \n",
    "    plt.title('actual {}'.format(targets[i].item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(2, num_samples, num_samples+i)\n",
    "    plt.imshow(np.squeeze(adversarial_examples[i]))\n",
    "    plt.title('{} {}'.format(pert_pred[i].item(), orig_pred[i].item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "TLhycjrBPl3j",
    "outputId": "95cf1f3b-b9b6-4e7e-ce52-939b0181eeba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9B1PnIm2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((o_best_adversaries[0] - inputs[0]).cpu().detach().numpy().reshape(28,28), cmap='gray') \n",
    "plt.title(targets[0].cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "iz2dUX8XNo_7",
    "outputId": "a0ba2290-5481-4e36-df4a-b50e8110f346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 95/100 (95%)\n",
      "\n",
      "\n",
      "Accuracy: 100/100 (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "correct = 0\n",
    "\n",
    "output = model(inputs)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "correct += pred.eq(targets.data.view_as(pred)).sum()\n",
    "\n",
    "acc = 100. * correct / len(targets)\n",
    "\n",
    "print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(targets), acc))\n",
    "\n",
    "# adversaries\n",
    "correct = 0\n",
    "\n",
    "output = model(o_best_adversaries)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "correct += pred.eq(targets.data.view_as(pred)).sum()\n",
    "\n",
    "acc = 100. * correct / len(targets)\n",
    "\n",
    "print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(targets), acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CW - pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
