{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CW_div_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yeR2kRlPR7v0",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import datetime\n",
        "import glob\n",
        "import os\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IByUFiD8VfFD",
        "outputId": "dbbb8d49-c9ae-4d28-a332-7965ec4963ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_epochs = 5\n",
        "batch_size_train = 64\n",
        "batch_size_test = 100\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 100\n",
        "\n",
        "random_seed = 1\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# check if CUDA is available\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print('CUDA is not available.  Training on CPU ...')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7l36L4F5VifU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a08d2a90-0431-4e47-b7cc-678b03de4f32"
      },
      "source": [
        "#  torchvision.transforms.Normalize(\n",
        "#    (0.1307,), (0.3081,))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/data/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor()\n",
        "                             ])),\n",
        "    batch_size=batch_size_train, shuffle=True, pin_memory=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/data/', train=False, download=True,\n",
        "                         transform=torchvision.transforms.Compose([\n",
        "                           torchvision.transforms.ToTensor()\n",
        "                         ])),\n",
        "    batch_size=batch_size_test, shuffle=True, pin_memory=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 7973054.86it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 128852.60it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2125393.89it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 49566.35it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yKEku0wcSCVQ",
        "colab": {}
      },
      "source": [
        "class DenseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.dens1 = nn.Linear(784, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.drop1 = nn.Dropout(0.2)\n",
        "        self.dens2 = nn.Linear(256, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.drop2 = nn.Dropout(0.2)\n",
        "        self.dens3 = nn.Linear(128, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.drop3 = nn.Dropout(0.2)\n",
        "        self.dens4 = nn.Linear(64, 20)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.drop4 = nn.Dropout(0.2)\n",
        "        self.dens5 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dens1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.drop1(x)\n",
        "        x = self.dens2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.drop2(x)\n",
        "        x = self.dens3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.drop3(x)\n",
        "        x = self.dens4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.drop4(x)\n",
        "        x = self.dens5(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "    def extract_outputs(self, data, layer, neuron=None):\n",
        "        outputs = []      \n",
        "        def hook(module, input, output):\n",
        "            outputs.append(output)    \n",
        "        for name, module in self.named_children():\n",
        "            if name == layer:\n",
        "                handle = module.register_forward_hook(hook)     \n",
        "        out = self(data)\n",
        "        if not neuron is None:\n",
        "            outputs[0] = outputs[0][0][neuron]\n",
        "        else:\n",
        "            outputs[0] = outputs[0][0]\n",
        "        handle.remove()\n",
        "        return torch.stack(outputs)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4 * 4 * 50)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "    def extract_outputs(self, data, layer, neuron=None):\n",
        "        outputs = []      \n",
        "        def hook(module, input, output):\n",
        "            outputs.append(output)    \n",
        "        for name, module in self.named_children():\n",
        "            if name == layer:\n",
        "                handle = module.register_forward_hook(hook)     \n",
        "        out = self(data)\n",
        "        if not neuron is None:\n",
        "            outputs[0] = outputs[0][0][neuron]\n",
        "        else:\n",
        "            outputs[0] = outputs[0][0]\n",
        "        handle.remove()\n",
        "        return torch.stack(outputs)\n",
        "  \n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # calculate robust loss\n",
        "        loss = F.cross_entropy(model(data), target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YCva0V7uVIZ_",
        "outputId": "ea5aac8d-f442-4e37-a6a3-25ae1e4b307f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = ConvNet().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "# check to see if we can just load a previous model\n",
        "%mkdir models\n",
        "latest_model = None\n",
        "m_type = model.__class__.__name__\n",
        "prev_models = glob.glob('/content/models/*'+ m_type +'*.pth')\n",
        "if prev_models:\n",
        "    latest_model = max(prev_models, key=os.path.getctime)\n",
        "\n",
        "if latest_model is not None and m_type in latest_model:\n",
        "    print('loading model', latest_model)\n",
        "    model.load_state_dict(torch.load(latest_model))  \n",
        "else:\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train(model, device, train_loader, optimizer, epoch)\n",
        "        test(model, device, test_loader)    \n",
        "    torch.save(model.state_dict(), '/content/models/model_' + m_type + '_' +str(datetime.datetime.now()).replace(':','.') + '.pth')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301512\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.191104\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.806484\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.701382\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.419531\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.603290\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.135957\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.227602\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.336506\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.158178\n",
            "\n",
            "Test set: Average loss: 0.1832, Accuracy: 9451/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.309578\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.161466\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.109566\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.126329\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.202263\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.079417\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.103295\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.058044\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.056968\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.083011\n",
            "\n",
            "Test set: Average loss: 0.1069, Accuracy: 9672/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.109435\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.098423\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.068376\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.117907\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.055617\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.051890\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.073384\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.110935\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.052715\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.038519\n",
            "\n",
            "Test set: Average loss: 0.0849, Accuracy: 9707/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.058056\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.074083\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.097400\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.062371\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.017662\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.024745\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.016720\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.094370\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.043104\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.088015\n",
            "\n",
            "Test set: Average loss: 0.0622, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.046443\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.064826\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.098531\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.060462\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.056099\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.087636\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.118126\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.230854\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.097971\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.041652\n",
            "\n",
            "Test set: Average loss: 0.0566, Accuracy: 9823/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_xXXilwbZq-v"
      },
      "source": [
        "# Attack Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Im4wutR6ge14",
        "colab": {}
      },
      "source": [
        "def atanh(x, eps=1e-2):\n",
        "    \"\"\"\n",
        "    The inverse hyperbolic tangent function, missing in pytorch.\n",
        "\n",
        "    :param x: a tensor or a Variable\n",
        "    :param eps: used to enhance numeric stability\n",
        "    :return: :math:`\\\\tanh^{-1}{x}`, of the same type as ``x``\n",
        "    \"\"\"\n",
        "    x = x * (1 - eps)\n",
        "    return 0.5 * torch.log((1.0 + x) / (1.0 - x))\n",
        "\n",
        "def to_tanh_space(x, box=(-1., 1.)):\n",
        "    \"\"\"\n",
        "    Convert a batch of tensors to tanh-space. This method complements the\n",
        "    implementation of the change-of-variable trick in terms of tanh.\n",
        "\n",
        "    :param x: the batch of tensors, of dimension [B x C x H x W]\n",
        "    :param box: a tuple of lower bound and upper bound of the box constraint\n",
        "    :return: the batch of tensors in tanh-space, of the same dimension;\n",
        "             the returned tensor is on the same device as ``x``\n",
        "    \"\"\"\n",
        "    _box_mul = (box[1] - box[0]) * 0.5\n",
        "    _box_plus = (box[1] + box[0]) * 0.5\n",
        "    return atanh((x - _box_plus) / _box_mul)\n",
        "\n",
        "def from_tanh_space(x, box=(-1., 1.)):\n",
        "    \"\"\"\n",
        "    Convert a batch of tensors from tanh-space to oridinary image space.\n",
        "    This method complements the implementation of the change-of-variable trick\n",
        "    in terms of tanh.\n",
        "\n",
        "    :param x: the batch of tensors, of dimension [B x C x H x W]\n",
        "    :param box: a tuple of lower bound and upper bound of the box constraint\n",
        "    :return: the batch of tensors in ordinary image space, of the same\n",
        "             dimension; the returned tensor is on the same device as ``x``\n",
        "    \"\"\"\n",
        "    _box_mul = (box[1] - box[0]) * 0.5\n",
        "    _box_plus = (box[1] + box[0]) * 0.5\n",
        "    return torch.tanh(x) * _box_mul + _box_plus\n",
        "  \n",
        "def compensate_confidence(outputs, targets):\n",
        "    \"\"\"\n",
        "    Compensate for ``self.confidence`` and returns a new weighted sum\n",
        "    vector.\n",
        "\n",
        "    :param outputs: the weighted sum right before the last layer softmax\n",
        "           normalization, of dimension [B x M]\n",
        "    :type outputs: np.ndarray\n",
        "    :param targets: either the attack targets or the real image labels,\n",
        "           depending on whether or not ``self.targeted``, of dimension [B]\n",
        "    :type targets: np.ndarray\n",
        "    :return: the compensated weighted sum of dimension [B x M]\n",
        "    :rtype: np.ndarray\n",
        "    \"\"\"\n",
        "    outputs_comp = outputs.clone()\n",
        "    rng = torch.range(start=0, end=targets.shape[0]-1, dtype=torch.long, device=device)\n",
        "    # targets = targets.int()\n",
        "    if targeted:\n",
        "        # for each image $i$:\n",
        "        # if targeted, `outputs[i, target_onehot]` should be larger than\n",
        "        # `max(outputs[i, ~target_onehot])` by `self.confidence`\n",
        "        outputs_comp[rng, targets] -= confidence\n",
        "    else:\n",
        "        # for each image $i$:\n",
        "        # if not targeted, `max(outputs[i, ~target_onehot]` should be larger\n",
        "        # than `outputs[i, target_onehot]` (the ground truth image labels)\n",
        "        # by `self.confidence`\n",
        "        outputs_comp[rng, targets] += confidence\n",
        "    return outputs_comp\n",
        "  \n",
        "def attack_successful(prediction, target):\n",
        "    \"\"\"\n",
        "    See whether the underlying attack is successful.\n",
        "\n",
        "    :param prediction: the prediction of the model on an input\n",
        "    :type prediction: int\n",
        "    :param target: either the attack target or the ground-truth image label\n",
        "    :type target: int\n",
        "    :return: ``True`` if the attack is successful\n",
        "    :rtype: bool\n",
        "    \"\"\"\n",
        "    if targeted:\n",
        "        return prediction == target\n",
        "    else:\n",
        "        return prediction != target\n",
        "      \n",
        "def norm_divergence(data, model, layer, neuron=None, regularizer_weight=None):\n",
        "    \"\"\"\n",
        "    returns the kld between the activations of the specified layer and a uniform pdf\n",
        "    \"\"\"\n",
        "    # extract layer activations as numpy array\n",
        "    layer_activations = model.extract_outputs(data=data, layer=layer)\n",
        "    \n",
        "    # normalize with softmax (to get a probability density)\n",
        "    out_norm = torch.sum(layer_activations, 0)\n",
        "    out_norm = F.softmax(out_norm, 0)\n",
        "\n",
        "    # create uniform tensor\n",
        "    uniform_tensor = torch.FloatTensor(*out_norm.shape).uniform_(0., 1.).to(device)\n",
        "\n",
        "    # normalize over summation (to get a probability density)\n",
        "    uni_norm = uniform_tensor/torch.sum(uniform_tensor)\n",
        "    \n",
        "    # measure divergence between normalized layer activations and uniform distribution\n",
        "    divergence = F.kl_div(input=out_norm.log(), target=uni_norm, reduction='sum')\n",
        "    \n",
        "    # default regularizer if not provided\n",
        "    if regularizer_weight is None:\n",
        "        regularizer_weight = 0.005 \n",
        "    \n",
        "    return regularizer_weight * divergence\n",
        "\n",
        "def eval_performance(model, originals, adversaries):\n",
        "    pert_output = model(adversaries)\n",
        "    orig_output = model(originals)\n",
        "\n",
        "    pert_pred = torch.argmax(pert_output, dim=1)\n",
        "    orig_pred = torch.argmax(orig_output, dim=1)\n",
        "\n",
        "    pert_correct = pert_pred.eq(targets.data).sum()\n",
        "    orig_correct = orig_pred.eq(targets.data).sum()\n",
        "\n",
        "    pert_acc = 100. * pert_correct / len(targets)\n",
        "    orig_acc = 100. * orig_correct / len(targets)\n",
        "\n",
        "    print('Perturbed Accuracy: {}/{} ({:.0f}%)\\n'.format(pert_correct, len(targets), pert_acc))\n",
        "    print('Original Accuracy: {}/{} ({:.0f}%)\\n'.format(orig_correct, len(targets), orig_acc))\n",
        "    \n",
        "    return pert_acc, orig_acc\n",
        "\n",
        "def sample_images(originals, adversaries, num_samples = 5):\n",
        "    orig_inputs = originals.cpu().detach().numpy()\n",
        "    adv_examples = adversaries.cpu().detach().numpy()\n",
        "    pert_output = model(adversaries)\n",
        "    orig_output = model(originals)\n",
        "    pert_pred = torch.argmax(pert_output, dim=1)\n",
        "    orig_pred = torch.argmax(orig_output, dim=1)\n",
        "    plt.figure(figsize=(15,8))\n",
        "    for i in range(1, num_samples+1):\n",
        "        plt.subplot(2, num_samples, i)\n",
        "        plt.imshow(np.squeeze(orig_inputs[i]), cmap='gray')  \n",
        "        plt.title('true: {}'.format(targets[i].item()))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "\n",
        "        plt.subplot(2, num_samples, num_samples+i)\n",
        "        plt.imshow(np.squeeze(adv_examples[i]), cmap='gray')\n",
        "        plt.title('adv_pred: {} - orig_pred: {}'.format(pert_pred[i].item(), orig_pred[i].item()))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X7o_T3B3dWzu",
        "colab": {}
      },
      "source": [
        "# targets = true labels only for when you're doing a targeted attack\n",
        "# otherwise, you're going to make the inputs easier to classify to \n",
        "# do a targeted attack, targets should be some class other than\n",
        "# the true label\n",
        "\n",
        "inputs, targets = next(iter(test_loader))\n",
        "\n",
        "inputs = inputs.to(device)\n",
        "targets = targets.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiGJy0r2h4aJ",
        "colab": {}
      },
      "source": [
        "def cw_l2_attack(model, inputs, targets, targeted=False, confidence=0.0,\n",
        "                 c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                 abort_early=True, box=(-1., 1.), optimizer_lr=1e-2, \n",
        "                 init_rand=False, log_frequency=10):\n",
        "\n",
        "    batch_size = inputs.size(0)\n",
        "    num_classes = model(torch.tensor(inputs[0][None,:], requires_grad=False)).size(1)\n",
        "\n",
        "    # `lower_bounds`, `upper_bounds` and `scale_consts` are used\n",
        "    # for binary search of each `scale_const` in the batch. The element-wise\n",
        "    # inquality holds: lower_bounds < scale_consts <= upper_bounds\n",
        "    lower_bounds = torch.tensor(np.zeros(batch_size), dtype=torch.float, device=device)\n",
        "    upper_bounds = torch.tensor(np.ones(batch_size) * c_range[1], dtype=torch.float, device=device)\n",
        "    scale_consts = torch.tensor(np.ones(batch_size) * c_range[0], dtype=torch.float, device=device)\n",
        "\n",
        "    # Optimal attack to be found.\n",
        "    # The three \"placeholders\" are defined as:\n",
        "    # - `o_best_l2`          : the least L2 norms\n",
        "    # - `o_best_l2_ppred`    : the perturbed predictions made by the adversarial perturbations with the least L2 norms\n",
        "    # - `o_best_adversaries` : the underlying adversarial example of `o_best_l2_ppred`\n",
        "    o_best_l2 = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
        "    o_best_l2_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
        "    o_best_adversaries = inputs.clone()\n",
        "\n",
        "    # convert `inputs` to tanh-space\n",
        "    inputs_tanh = to_tanh_space(inputs)\n",
        "    targets_oh = F.one_hot(targets).float()\n",
        "\n",
        "    # the perturbation tensor (only one we need to track gradients on)\n",
        "    pert_tanh = torch.zeros(inputs.size(), device=device, requires_grad=True)\n",
        "\n",
        "    optimizer = optim.Adam([pert_tanh], lr=optimizer_lr)\n",
        "\n",
        "    for const_step in range(search_steps):\n",
        "\n",
        "        print('Step', const_step)\n",
        "\n",
        "        # the minimum L2 norms of perturbations found during optimization\n",
        "        best_l2 = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
        "\n",
        "        # the perturbed predictions made by the adversarial perturbations with the least L2 norms\n",
        "        best_l2_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
        "\n",
        "        # previous (summed) batch loss, to be used in early stopping policy\n",
        "        prev_batch_loss = torch.tensor(np.inf, device=device)\n",
        "        ae_tol = torch.tensor(1e-4, device=device)\n",
        "\n",
        "        # optimization steps\n",
        "        for optim_step in range(max_steps):\n",
        "\n",
        "            adversaries = from_tanh_space(inputs_tanh + pert_tanh)\n",
        "            pert_outputs = model(adversaries)\n",
        "\n",
        "            # Calculate L2 norm between adversaries and original inputs\n",
        "            pert_norms = torch.pow(adversaries - inputs, exponent=2)\n",
        "            pert_norms = torch.sum(pert_norms.view(pert_norms.size(0), -1), 1)\n",
        "\n",
        "            target_activ = torch.sum(targets_oh * pert_outputs, 1)\n",
        "            maxother_activ = torch.max(((1 - targets_oh) * pert_outputs - targets_oh * 1e4), 1)[0]\n",
        "\n",
        "            if targeted:           \n",
        "                # if targeted, optimize to make `target_activ` larger than `maxother_activ` by `confidence`\n",
        "                f = torch.clamp(maxother_activ - target_activ + confidence, min=0.0)\n",
        "            else:\n",
        "                # if not targeted, optimize to make `maxother_activ` larger than `target_activ` (the ground truth image labels) by `confidence`\n",
        "                f = torch.clamp(target_activ - maxother_activ + confidence, min=0.0)\n",
        "\n",
        "            # the total loss of current batch, should be of dimension [1]\n",
        "            batch_loss = torch.sum(pert_norms + scale_consts * f)\n",
        "\n",
        "            # Do optimization for one step\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # \"returns\" batch_loss, pert_norms, pert_outputs, adversaries\n",
        "\n",
        "            if optim_step % log_frequency == 0: \n",
        "                print('batch [{}] loss: {}'.format(optim_step, batch_loss))\n",
        "\n",
        "            if abort_early and not optim_step % (max_steps // 10):   \n",
        "                if batch_loss > prev_batch_loss * (1 - ae_tol):\n",
        "                    break\n",
        "                prev_batch_loss = batch_loss\n",
        "\n",
        "            # update best attack found during optimization\n",
        "            pert_predictions = torch.argmax(pert_outputs, dim=1)\n",
        "            comp_pert_predictions = torch.argmax(compensate_confidence(pert_outputs, targets), dim=1)\n",
        "            for i in range(batch_size):\n",
        "                l2 = pert_norms[i]\n",
        "                cppred = comp_pert_predictions[i]\n",
        "                ppred = pert_predictions[i]\n",
        "                tlabel = targets[i]\n",
        "                ax = adversaries[i]\n",
        "                if attack_successful(cppred, tlabel):\n",
        "                    assert cppred == ppred\n",
        "                    if l2 < best_l2[i]:\n",
        "                        best_l2[i] = l2\n",
        "                        best_l2_ppred[i] = ppred\n",
        "                    if l2 < o_best_l2[i]:\n",
        "                        o_best_l2[i] = l2\n",
        "                        o_best_l2_ppred[i] = ppred\n",
        "                        o_best_adversaries[i] = ax\n",
        "\n",
        "        # binary search of `scale_const`\n",
        "        for i in range(batch_size):\n",
        "            tlabel = targets[i]\n",
        "            if best_l2_ppred[i] != -1:\n",
        "                # successful: attempt to lower `scale_const` by halving it\n",
        "                if scale_consts[i] < upper_bounds[i]:\n",
        "                    upper_bounds[i] = scale_consts[i]\n",
        "                # `upper_bounds[i] == c_range[1]` implies no solution\n",
        "                # found, i.e. upper_bounds[i] has never been updated by\n",
        "                # scale_consts[i] until `scale_consts[i] > 0.1 * c_range[1]`\n",
        "                if upper_bounds[i] < c_range[1] * 0.1:\n",
        "                    scale_consts[i] = (lower_bounds[i] + upper_bounds[i]) / 2\n",
        "            else:\n",
        "                # failure: multiply `scale_const` by ten if no solution\n",
        "                # found; otherwise do binary search\n",
        "                if scale_consts[i] > lower_bounds[i]:\n",
        "                    lower_bounds[i] = scale_consts[i]\n",
        "                if upper_bounds[i] < c_range[1] * 0.1:\n",
        "                    scale_consts[i] = (lower_bounds[i] + upper_bounds[i]) / 2\n",
        "                else:\n",
        "                    scale_consts[i] *= 10\n",
        "                    \n",
        "    return o_best_adversaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VbAGYjiGODjF",
        "colab": {}
      },
      "source": [
        "targeted=False\n",
        "confidence=0.0\n",
        "c_range=(1e-3, 1e10)\n",
        "search_steps=10\n",
        "max_steps=1000\n",
        "abort_early=True\n",
        "optimizer_lr=5e-4\n",
        "\n",
        "mean = (0.1307,) # the mean used in inputs normalization\n",
        "std = (0.3081,) # the standard deviation used in inputs normalization\n",
        "box = (min((0 - m) / s for m, s in zip(mean, std)),\n",
        "       max((1 - m) / s for m, s in zip(mean, std)))\n",
        "\n",
        "log_frequency = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kLueeAz4_-MO",
        "outputId": "8a3cedb3-4761-4850-d961-3a5a1010c652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "cw_advs = cw_l2_attack(model, inputs, targets, targeted=False, confidence=0.0,\n",
        "                       c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                       abort_early=True, box=box, optimizer_lr=5e-4, \n",
        "                       init_rand=False, log_frequency=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0\n",
            "batch [0] loss: 1.6486514806747437\n",
            "batch [100] loss: 1.1929818391799927\n",
            "batch [200] loss: 1.0596026182174683\n",
            "batch [300] loss: 0.9751903414726257\n",
            "batch [400] loss: 0.9173973202705383\n",
            "batch [500] loss: 0.8763886094093323\n",
            "batch [600] loss: 0.8465988636016846\n",
            "batch [700] loss: 0.8245663046836853\n",
            "batch [800] loss: 0.8080291748046875\n",
            "batch [900] loss: 0.7954586744308472\n",
            "Step 1\n",
            "batch [0] loss: 7.470940589904785\n",
            "batch [100] loss: 7.427858829498291\n",
            "batch [200] loss: 7.420724868774414\n",
            "batch [300] loss: 7.415339469909668\n",
            "batch [400] loss: 7.41116189956665\n",
            "batch [500] loss: 7.407866954803467\n",
            "batch [600] loss: 7.405221939086914\n",
            "batch [700] loss: 7.403077125549316\n",
            "batch [800] loss: 7.401312351226807\n",
            "batch [900] loss: 7.399847984313965\n",
            "Step 2\n",
            "batch [0] loss: 73.40937805175781\n",
            "batch [100] loss: 69.4816665649414\n",
            "batch [200] loss: 69.17349243164062\n",
            "batch [300] loss: 68.95938873291016\n",
            "batch [400] loss: 68.8092269897461\n",
            "batch [500] loss: 68.70639038085938\n",
            "batch [600] loss: 68.63870239257812\n",
            "batch [700] loss: 68.59515380859375\n",
            "batch [800] loss: 68.56848907470703\n",
            "batch [900] loss: 68.55079650878906\n",
            "Step 3\n",
            "batch [0] loss: 632.5966796875\n",
            "batch [100] loss: 343.6021728515625\n",
            "batch [200] loss: 313.21783447265625\n",
            "batch [300] loss: 298.9659118652344\n",
            "batch [400] loss: 289.5364990234375\n",
            "batch [500] loss: 282.9603576660156\n",
            "batch [600] loss: 277.88525390625\n",
            "batch [700] loss: 273.8846740722656\n",
            "batch [800] loss: 270.9686279296875\n",
            "batch [900] loss: 268.952392578125\n",
            "Step 4\n",
            "batch [0] loss: 576.1707153320312\n",
            "batch [100] loss: 277.81121826171875\n",
            "batch [200] loss: 271.5420837402344\n",
            "batch [300] loss: 269.0086975097656\n",
            "batch [400] loss: 267.44873046875\n",
            "batch [500] loss: 266.3844909667969\n",
            "batch [600] loss: 265.6120910644531\n",
            "batch [700] loss: 265.01214599609375\n",
            "batch [800] loss: 264.5208740234375\n",
            "batch [900] loss: 264.15557861328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CUsvsyleV1Is",
        "outputId": "8bdaf0ca-903b-4871-c249-456f949ae275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "eval_performance(model, inputs, cw_advs)\n",
        "sample_images(inputs, cw_advs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perturbed Accuracy: 0/100 (0%)\n",
            "\n",
            "Original Accuracy: 99/100 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TLhycjrBPl3j",
        "outputId": "080b9c4b-e448-4118-b69b-e7f3ab829ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.imshow((cw_advs[1] - inputs[1]).cpu().detach().numpy().reshape(28,28), cmap='gray') \n",
        "plt.title(targets[1].cpu().numpy())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4PMv-KEuX9Q2"
      },
      "source": [
        "# Diversity Attack v1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MiwScd1eX1eJ",
        "colab": {}
      },
      "source": [
        "def cw_div_attack(model, inputs, targets, targeted=False, confidence=0.0,\n",
        "                  c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                  abort_early=True, box=(-1., 1.), optimizer_lr=1e-2, \n",
        "                  init_rand=False, log_frequency=10):\n",
        "\n",
        "    batch_size = inputs.size(0)\n",
        "    num_classes = model(torch.tensor(inputs[0][None,:], requires_grad=False)).size(1)\n",
        "\n",
        "    # `lower_bounds`, `upper_bounds` and `scale_consts` are used\n",
        "    # for binary search of each `scale_const` in the batch. The element-wise\n",
        "    # inquality holds: lower_bounds < scale_consts <= upper_bounds\n",
        "    lower_bounds = torch.tensor(np.zeros(batch_size), dtype=torch.float, device=device)\n",
        "    upper_bounds = torch.tensor(np.ones(batch_size) * c_range[1], dtype=torch.float, device=device)\n",
        "    scale_consts = torch.tensor(np.ones(batch_size) * c_range[0], dtype=torch.float, device=device)\n",
        "\n",
        "    # Optimal attack to be found.\n",
        "    # The three \"placeholders\" are defined as:\n",
        "    # - `o_best_div`         : the least divergences\n",
        "    # - `o_best_div_ppred`   : the perturbed predictions made by the adversarial perturbations with the least divergences\n",
        "    # - `o_best_adversaries` : the underlying adversarial example of `o_best_div_ppred`\n",
        "    o_best_div = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
        "    o_best_div_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
        "    o_best_adversaries = inputs.clone()\n",
        "\n",
        "    # convert `inputs` to tanh-space\n",
        "    inputs_tanh = to_tanh_space(inputs)\n",
        "    targets_oh = F.one_hot(targets).float()\n",
        "\n",
        "    # the perturbation tensor (only one we need to track gradients on)\n",
        "    pert_tanh = torch.zeros(inputs.size(), device=device, requires_grad=True)\n",
        "\n",
        "    optimizer = optim.Adam([pert_tanh], lr=optimizer_lr)\n",
        "\n",
        "    for const_step in range(1):\n",
        "\n",
        "        print('Step', const_step)\n",
        "\n",
        "        # the minimum divergences of perturbations found during optimization\n",
        "        best_div = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
        "\n",
        "        # the perturbed predictions made by the adversarial perturbations with the least divergences\n",
        "        best_div_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
        "\n",
        "        # previous (summed) batch loss, to be used in early stopping policy\n",
        "        prev_batch_loss = torch.tensor(np.inf, device=device)\n",
        "        ae_tol = torch.tensor(1e-4, device=device)\n",
        "\n",
        "        # optimization steps\n",
        "        for optim_step in range(max_steps):\n",
        "\n",
        "            adversaries = from_tanh_space(inputs_tanh + pert_tanh)\n",
        "            pert_outputs = model(adversaries)\n",
        "\n",
        "            # calculate kl divergence for each input\n",
        "            divs = []\n",
        "            for i in range(batch_size):\n",
        "                divs.append(norm_divergence(data=adversaries[i].unsqueeze(0), model=model, layer='relu3', regularizer_weight=1))\n",
        "\n",
        "            div_norms = torch.tensor(torch.stack(divs), device=device)\n",
        "\n",
        "            target_activ = torch.sum(targets_oh * pert_outputs, 1)\n",
        "            maxother_activ = torch.max(((1 - targets_oh) * pert_outputs - targets_oh * 1e4), 1)[0]\n",
        "\n",
        "            if targeted:           \n",
        "                # if targeted, optimize to make `target_activ` larger than `maxother_activ` by `confidence`\n",
        "                f = torch.clamp(maxother_activ - target_activ + confidence, min=0.0)\n",
        "            else:\n",
        "                # if not targeted, optimize to make `maxother_activ` larger than `target_activ` (the ground truth image labels) by `confidence`\n",
        "                f = torch.clamp(target_activ - maxother_activ + confidence, min=0.0)\n",
        "\n",
        "    #         # diversity regularizer\n",
        "    #         diversity_reg = norm_divergence(data=adversaries, model=model, layer='relu3', regularizer_weight=1)\n",
        "\n",
        "            # the total loss of current batch, should be of dimension [1]\n",
        "            batch_loss = torch.sum(scale_consts * f + div_norms) # + diversity_reg\n",
        "\n",
        "            # Do optimization for one step\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # \"returns\" batch_loss, pert_norms, pert_outputs, adversaries\n",
        "\n",
        "            if optim_step % log_frequency == 0: \n",
        "                print('batch [{}] loss: {}'.format(optim_step, batch_loss))\n",
        "\n",
        "            if abort_early and not optim_step % (max_steps // 10):   \n",
        "                if batch_loss > prev_batch_loss * (1 - ae_tol):\n",
        "                    break\n",
        "                prev_batch_loss = batch_loss\n",
        "\n",
        "            # update best attack found during optimization\n",
        "            pert_predictions = torch.argmax(pert_outputs, dim=1)\n",
        "            comp_pert_predictions = torch.argmax(compensate_confidence(pert_outputs, targets), dim=1)\n",
        "            for i in range(batch_size):\n",
        "                div = div_norms[i]\n",
        "                cppred = comp_pert_predictions[i]\n",
        "                ppred = pert_predictions[i]\n",
        "                tlabel = targets[i]\n",
        "                ax = adversaries[i]\n",
        "                if attack_successful(cppred, tlabel):\n",
        "                    assert cppred == ppred\n",
        "                    if div < best_div[i]:\n",
        "                        best_div[i] = div\n",
        "                        best_div_ppred[i] = ppred\n",
        "                    if div < o_best_div[i]:\n",
        "                        o_best_div[i] = div\n",
        "                        o_best_div_ppred[i] = ppred\n",
        "                        o_best_adversaries[i] = ax\n",
        "\n",
        "        # binary search of `scale_const`\n",
        "        for i in range(batch_size):\n",
        "            tlabel = targets[i]\n",
        "            if best_div_ppred[i] != -1:\n",
        "                # successful: attempt to lower `scale_const` by halving it\n",
        "                if scale_consts[i] < upper_bounds[i]:\n",
        "                    upper_bounds[i] = scale_consts[i]\n",
        "                # `upper_bounds[i] == c_range[1]` implies no solution\n",
        "                # found, i.e. upper_bounds[i] has never been updated by\n",
        "                # scale_consts[i] until `scale_consts[i] > 0.1 * c_range[1]`\n",
        "                if upper_bounds[i] < c_range[1] * 0.1:\n",
        "                    scale_consts[i] = (lower_bounds[i] + upper_bounds[i]) / 2\n",
        "            else:\n",
        "                # failure: multiply `scale_const` by ten if no solution\n",
        "                # found; otherwise do binary search\n",
        "                if scale_consts[i] > lower_bounds[i]:\n",
        "                    lower_bounds[i] = scale_consts[i]\n",
        "                if upper_bounds[i] < c_range[1] * 0.1:\n",
        "                    scale_consts[i] = (lower_bounds[i] + upper_bounds[i]) / 2\n",
        "                else:\n",
        "                    scale_consts[i] *= 10\n",
        "                    \n",
        "    return o_best_adversaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BU2t6ERVB6C3",
        "outputId": "2f916a1f-7dcc-4b69-ec6e-7e700285f37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "cw_advs_div = cw_div_attack(model, inputs, targets, targeted=False, confidence=0.0,\n",
        "                            c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                            abort_early=True, box=box, optimizer_lr=5e-4, \n",
        "                            init_rand=False, log_frequency=100)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0\n",
            "batch [0] loss: 125.08393096923828\n",
            "batch [100] loss: 118.01533508300781\n",
            "batch [200] loss: 113.60195922851562\n",
            "batch [300] loss: 110.04512023925781\n",
            "batch [400] loss: 107.70555114746094\n",
            "batch [500] loss: 106.78938293457031\n",
            "batch [600] loss: 107.2767333984375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c651LtJEbi56",
        "outputId": "4584ef1f-9e2b-4be6-cec8-3b0a9655c1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "eval_performance(model, inputs, cw_advs_div)\n",
        "sample_images(inputs, cw_advs_div)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perturbed Accuracy: 2/100 (2%)\n",
            "\n",
            "Original Accuracy: 98/100 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCwAAAHrCAYAAAAExww7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x576 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzVUYdHrRczQ",
        "colab_type": "text"
      },
      "source": [
        "# Diversity Attack v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRG0FJayRLyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cw_div2_attack(model, inputs, targets, targeted=False, confidence=0.0,\n",
        "                   c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                   abort_early=True, box=(-1., 1.), optimizer_lr=1e-2, \n",
        "                   init_rand=False, log_frequency=10):\n",
        "\n",
        "    batch_size = inputs.size(0)\n",
        "    num_classes = model(torch.tensor(inputs[0][None,:], requires_grad=False)).size(1)\n",
        "\n",
        "    # Optimal attack to be found.\n",
        "    # The three \"placeholders\" are defined as:\n",
        "    # - `o_best_div`         : the least divergences\n",
        "    # - `o_best_div_ppred`   : the perturbed predictions made by the adversarial perturbations with the least divergences\n",
        "    # - `o_best_adversaries` : the underlying adversarial example of `o_best_div_ppred`\n",
        "    o_best_div = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
        "    o_best_div_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
        "    o_best_adversaries = inputs.clone()\n",
        "\n",
        "    # convert `inputs` to tanh-space\n",
        "    inputs_tanh = to_tanh_space(inputs)\n",
        "    targets_oh = F.one_hot(targets).float()\n",
        "\n",
        "    # the perturbation tensor (only one we need to track gradients on)\n",
        "    pert_tanh = torch.zeros(inputs.size(), device=device, requires_grad=True)\n",
        "\n",
        "    optimizer = optim.Adam([pert_tanh], lr=optimizer_lr)\n",
        "\n",
        "    # the minimum divergences of perturbations found during optimization\n",
        "    best_div = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
        "\n",
        "    # the perturbed predictions made by the adversarial perturbations with the least divergences\n",
        "    best_div_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
        "\n",
        "    # previous (summed) batch loss, to be used in early stopping policy\n",
        "    prev_batch_loss = torch.tensor(np.inf, device=device)\n",
        "    ae_tol = torch.tensor(1e-4, device=device)\n",
        "\n",
        "    # optimization steps\n",
        "    for optim_step in range(max_steps):\n",
        "\n",
        "        adversaries = from_tanh_space(inputs_tanh + pert_tanh)\n",
        "        pert_outputs = model(adversaries)\n",
        "\n",
        "        # calculate kl divergence for each input\n",
        "        divs = []\n",
        "        for i in range(batch_size):\n",
        "            divs.append(norm_divergence(data=adversaries[i].unsqueeze(0), model=model, layer='relu3', regularizer_weight=1))\n",
        "\n",
        "        div_norms = torch.tensor(torch.stack(divs), device=device)\n",
        "\n",
        "        target_activ = torch.sum(targets_oh * pert_outputs, 1)\n",
        "        maxother_activ = torch.max(((1 - targets_oh) * pert_outputs - targets_oh * 1e4), 1)[0]\n",
        "\n",
        "        if targeted:           \n",
        "            # if targeted, optimize to make `target_activ` larger than `maxother_activ` by `confidence`\n",
        "            f = torch.clamp(maxother_activ - target_activ + confidence, min=0.0)\n",
        "        else:\n",
        "            # if not targeted, optimize to make `maxother_activ` larger than `target_activ` (the ground truth image labels) by `confidence`\n",
        "            f = torch.clamp(target_activ - maxother_activ + confidence, min=0.0)\n",
        "\n",
        "        # the total loss of current batch, should be of dimension [1]\n",
        "        batch_loss = torch.sum(f + div_norms) # + diversity_reg\n",
        "\n",
        "        # Do optimization for one step\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # \"returns\" batch_loss, pert_norms, pert_outputs, adversaries\n",
        "\n",
        "        if optim_step % log_frequency == 0: \n",
        "            print('batch [{}] loss: {}'.format(optim_step, batch_loss))\n",
        "\n",
        "        if abort_early and not optim_step % (max_steps // 10):   \n",
        "            if batch_loss > prev_batch_loss * (1 - ae_tol):\n",
        "                break\n",
        "            prev_batch_loss = batch_loss\n",
        "\n",
        "        # update best attack found during optimization\n",
        "        pert_predictions = torch.argmax(pert_outputs, dim=1)\n",
        "        comp_pert_predictions = torch.argmax(compensate_confidence(pert_outputs, targets), dim=1)\n",
        "        for i in range(batch_size):\n",
        "            div = div_norms[i]\n",
        "            cppred = comp_pert_predictions[i]\n",
        "            ppred = pert_predictions[i]\n",
        "            tlabel = targets[i]\n",
        "            ax = adversaries[i]\n",
        "            if attack_successful(cppred, tlabel):\n",
        "                assert cppred == ppred\n",
        "                if div < best_div[i]:\n",
        "                    best_div[i] = div\n",
        "                    best_div_ppred[i] = ppred\n",
        "                if div < o_best_div[i]:\n",
        "                    o_best_div[i] = div\n",
        "                    o_best_div_ppred[i] = ppred\n",
        "                    o_best_adversaries[i] = ax\n",
        "                    \n",
        "    return o_best_adversaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6KVf6RRRLyn",
        "colab_type": "code",
        "outputId": "db262597-7260-4732-91e7-db898c4bb466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cw_advs_div2 = cw_div2_attack(model, inputs, targets, targeted=False, confidence=0.0,\n",
        "                              c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                              abort_early=True, box=box, optimizer_lr=5e-4, \n",
        "                              init_rand=False, log_frequency=100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch [0] loss: 876.9237060546875\n",
            "batch [100] loss: 614.6558837890625\n",
            "batch [200] loss: 386.7690124511719\n",
            "batch [300] loss: 234.40536499023438\n",
            "batch [400] loss: 153.71673583984375\n",
            "batch [500] loss: 119.77983093261719\n",
            "batch [600] loss: 110.68762969970703\n",
            "batch [700] loss: 107.66962432861328\n",
            "batch [800] loss: 106.90571594238281\n",
            "batch [900] loss: 107.4959716796875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FjU2g0jRLy1",
        "colab_type": "code",
        "outputId": "4f394f31-7dd7-4d66-ab99-9bb97c4d892e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "eval_performance(model, inputs, cw_advs_div2)\n",
        "sample_images(inputs, cw_advs_div2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perturbed Accuracy: 0/100 (0%)\n",
            "\n",
            "Original Accuracy: 98/100 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCwAAAHrCAYAAAAExww7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAgddiwAAAAAAAAqfM/eGX4YolSO2YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x576 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63AbLZogRLzE",
        "colab_type": "code",
        "outputId": "fd26755d-7682-4321-accd-171aed7a187e",
        "colab": {}
      },
      "source": [
        "cw_advs.equal(cw_advs_div)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJRhdV5aRLzP",
        "colab_type": "code",
        "outputId": "9329d136-81a8-4119-e5b8-bfd0fc01c4c6",
        "colab": {}
      },
      "source": [
        "cw_advs_div.equal(cw_advs_div2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8SHpsaSRLzX",
        "colab_type": "code",
        "outputId": "eb3bdd88-5e1f-4640-b082-7a32525ced89",
        "colab": {}
      },
      "source": [
        "cw_advs.equal(cw_advs_div2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivE3YOQIRLzh",
        "colab_type": "code",
        "outputId": "b050b669-f87f-47c4-f1c4-86b963baf7cd",
        "colab": {}
      },
      "source": [
        "cw_advs.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3130, -0.3130, -0.3087,  ...,  0.9999,  0.9999,  0.9999],\n",
              "       device='cuda:0', grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzFWidecRLzo",
        "colab_type": "code",
        "outputId": "734dc209-457d-4b33-accf-922713592e21",
        "colab": {}
      },
      "source": [
        "cw_advs_div.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4568, -0.4521, -0.4480,  ...,  0.9941,  0.9941,  0.9943],\n",
              "       device='cuda:0', grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t97ieYCkRLzz",
        "colab_type": "text"
      },
      "source": [
        "# Diversity Attack v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuEKLdemRLz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cw_div3_attack(model, layer, regularizer_weight, inputs, targets, targeted=False, \n",
        "                   confidence=0.0, c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                   abort_early=True, box=(-1., 1.), optimizer_lr=1e-2, \n",
        "                   init_rand=False, log_frequency=10):\n",
        "\n",
        "    batch_size = inputs.size(0)\n",
        "    num_classes = model(torch.tensor(inputs[0][None,:], requires_grad=False)).size(1)\n",
        "\n",
        "    # Optimal attack to be found.\n",
        "    # The three \"placeholders\" are defined as:\n",
        "    # - `o_best_div`         : the least divergences\n",
        "    # - `o_best_div_ppred`   : the perturbed predictions made by the adversarial perturbations with the least divergences\n",
        "    # - `o_best_adversaries` : the underlying adversarial example of `o_best_div_ppred`\n",
        "    o_best_div = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
        "    o_best_div_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
        "    o_best_adversaries = inputs.clone()\n",
        "\n",
        "    # convert `inputs` to tanh-space\n",
        "    inputs_tanh = to_tanh_space(inputs)\n",
        "    targets_oh = F.one_hot(targets).float()\n",
        "\n",
        "    # the perturbation tensor (only one we need to track gradients on)\n",
        "    pert_tanh = torch.zeros(inputs.size(), device=device, requires_grad=True)\n",
        "\n",
        "    optimizer = optim.Adam([pert_tanh], lr=optimizer_lr)\n",
        "\n",
        "    # the minimum divergences of perturbations found during optimization\n",
        "    best_div = torch.tensor(np.ones(batch_size) * np.inf, dtype=torch.float, device=device)\n",
        "\n",
        "    # the perturbed predictions made by the adversarial perturbations with the least divergences\n",
        "    best_div_ppred = torch.tensor(-np.ones(batch_size), dtype=torch.float, device=device)\n",
        "\n",
        "    # previous (summed) batch loss, to be used in early stopping policy\n",
        "    prev_batch_loss = torch.tensor(np.inf, device=device)\n",
        "    ae_tol = torch.tensor(1e-4, device=device)\n",
        "\n",
        "    # optimization steps\n",
        "    for optim_step in range(max_steps):\n",
        "\n",
        "        adversaries = from_tanh_space(inputs_tanh + pert_tanh)\n",
        "        pert_outputs = model(adversaries)\n",
        "\n",
        "        # calculate kl divergence for each input\n",
        "        divs = []\n",
        "        for i in range(batch_size):\n",
        "            divs.append(norm_divergence(data=adversaries[i].unsqueeze(0), model=model, layer=layer, regularizer_weight=regularizer_weight))\n",
        "\n",
        "        div_norms = torch.tensor(torch.stack(divs), device=device)\n",
        "\n",
        "        loss = -1. * nn.CrossEntropyLoss()(pert_outputs, targets)\n",
        "\n",
        "        # the total loss of current batch, should be of dimension [1]\n",
        "        batch_loss = torch.sum(loss + div_norms) \n",
        "\n",
        "        # Do optimization for one step\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # \"returns\" batch_loss, pert_norms, pert_outputs, adversaries\n",
        "\n",
        "        if optim_step % log_frequency == 0: \n",
        "            print('batch [{}] loss: {}'.format(optim_step, batch_loss))\n",
        "\n",
        "        if abort_early and not optim_step % (max_steps // 10):   \n",
        "            if batch_loss > prev_batch_loss * (1 - ae_tol):\n",
        "                break\n",
        "            prev_batch_loss = batch_loss\n",
        "\n",
        "        # update best attack found during optimization\n",
        "        pert_predictions = torch.argmax(pert_outputs, dim=1)\n",
        "        comp_pert_predictions = torch.argmax(compensate_confidence(pert_outputs, targets), dim=1)\n",
        "        for i in range(batch_size):\n",
        "            div = div_norms[i]\n",
        "            cppred = comp_pert_predictions[i]\n",
        "            ppred = pert_predictions[i]\n",
        "            tlabel = targets[i]\n",
        "            ax = adversaries[i]\n",
        "            if attack_successful(cppred, tlabel):\n",
        "                assert cppred == ppred\n",
        "                if div < best_div[i]:\n",
        "                    best_div[i] = div\n",
        "                    best_div_ppred[i] = ppred\n",
        "                if div < o_best_div[i]:\n",
        "                    o_best_div[i] = div\n",
        "                    o_best_div_ppred[i] = ppred\n",
        "                    o_best_adversaries[i] = ax\n",
        "                    \n",
        "    return o_best_adversaries, div_norms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqEO2jx8RLz8",
        "colab_type": "code",
        "outputId": "ed9e0661-d607-4a46-c95c-6c5e989b4f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "cw_advs_div3 = cw_div3_attack(model, 'relu3', 1, inputs, targets, targeted=False, confidence=0.0,\n",
        "                              c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                              abort_early=True, box=box, optimizer_lr=5e-4, \n",
        "                              init_rand=False, log_frequency=100)\n",
        "\n",
        "eval_performance(model, inputs, cw_advs_div3)\n",
        "sample_images(inputs, cw_advs_div3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch [0] loss: 126.80441284179688\n",
            "batch [100] loss: 98.60725402832031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-85a295993072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mc_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mabort_early\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               init_rand=False, log_frequency=100)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0meval_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw_advs_div3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-f7fe10909043>\u001b[0m in \u001b[0;36mcw_div3_attack\u001b[0;34m(model, layer, regularizer_weight, inputs, targets, targeted, confidence, c_range, search_steps, max_steps, abort_early, box, optimizer_lr, init_rand, log_frequency)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdivs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mdivs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madversaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdiv_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-e55e87ad1ced>\u001b[0m in \u001b[0;36mnorm_divergence\u001b[0;34m(data, model, layer, neuron, regularizer_weight)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \"\"\"\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# extract layer activations as numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mlayer_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# normalize with softmax (to get a probability density)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-561528d6c307>\u001b[0m in \u001b[0;36mextract_outputs\u001b[0;34m(self, data, layer, neuron)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-561528d6c307>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiTyG5O1RL0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow((cw_advs_div3[1] - inputs[1]).cpu().detach().numpy().reshape(28,28), cmap='gray') \n",
        "plt.title(targets[1].cpu().numpy())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZhv8nkJRL0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(inputs[1] - cw_advs_div[1]).unique().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo0_HOLTdnKe",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKgn1boNRL0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "5853faa9-076f-4eeb-a0cc-603c064b0493"
      },
      "source": [
        "results = []\n",
        "\n",
        "all_layers = list(dict(model.named_children()))\n",
        "target_layers = [layer for layer in all_layers if 'relu' in layer] # [layer for layer in all_layers if 'pool' not in layer and 'flatten' not in layer and 'input' not in layer]\n",
        "\n",
        "for l in target_layers:\n",
        "    for rw in [0.01, 0.1, 1, 5, 10]:\n",
        "        print('layer: ', l, 'regularization_weight: ', rw)\n",
        "        cw_advs_divs, divergences = cw_div3_attack(model, l, rw, inputs, targets, targeted=False, confidence=0.0,\n",
        "                                                   c_range=(1e-3, 1e10), search_steps=5, max_steps=1000, \n",
        "                                                   abort_early=True, box=box, optimizer_lr=5e-4, \n",
        "                                                   init_rand=False, log_frequency=100)\n",
        "\n",
        "        pert_acc, orig_acc = eval_performance(model, inputs, cw_advs_divs)\n",
        "        sample_images(inputs, cw_advs_divs)\n",
        "        \n",
        "        out = {'layer': l, 'regularization_weight': rw, 'adversaries': cw_advs_divs, 'divergences':divergences, 'pert_acc':pert_acc, 'orig_acc': orig_acc}\n",
        "        results.append(out)\n",
        "        \n",
        "results"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer relu1 regularization_weight 0.01\n",
            "batch [0] loss: 126.52732849121094\n",
            "batch [100] loss: 98.60231018066406\n",
            "batch [200] loss: -150.12452697753906\n",
            "batch [300] loss: -541.1753540039062\n",
            "batch [400] loss: -854.880126953125\n",
            "batch [500] loss: -1111.86962890625\n",
            "batch [600] loss: -1327.406005859375\n",
            "batch [700] loss: -1514.053466796875\n",
            "batch [800] loss: -1680.046142578125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-e43f1407b96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                    \u001b[0mc_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                    \u001b[0mabort_early\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                    init_rand=False, log_frequency=100)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpert_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw_advs_divs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-f7fe10909043>\u001b[0m in \u001b[0;36mcw_div3_attack\u001b[0;34m(model, layer, regularizer_weight, inputs, targets, targeted, confidence, c_range, search_steps, max_steps, abort_early, box, optimizer_lr, init_rand, log_frequency)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdivs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mdivs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madversaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdiv_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-e55e87ad1ced>\u001b[0m in \u001b[0;36mnorm_divergence\u001b[0;34m(data, model, layer, neuron, regularizer_weight)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \"\"\"\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# extract layer activations as numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mlayer_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# normalize with softmax (to get a probability density)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-561528d6c307>\u001b[0m in \u001b[0;36mextract_outputs\u001b[0;34m(self, data, layer, neuron)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-561528d6c307>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.73 GiB total capacity; 13.92 GiB already allocated; 3.94 MiB free; 46.38 MiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt1vvsHPe6Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}